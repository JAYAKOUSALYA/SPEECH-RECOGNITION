# ğŸ™ï¸ Speech Recognition Projects Suite

A collection of deep learning-based audio recognition systems focused on voice-driven automation and safety.  
This suite includes:

- ğŸ˜¨ **Fear Detection** from voice for triggering security alerts
- ğŸ—£ï¸ **Speech-to-Text** transcription using the Google Speech Command dataset
- ğŸ”¢ **Digit Recognition (0â€“9)** from spoken audio using the same dataset

---

## ğŸ” Project 1: Fear Detection for Security Alert

### ğŸ“Œ Description:
Detects **fear emotion** in human voice using audio classification. Upon detection, it can **trigger a security alert** such as logging, sound alarms, or sending emails.

### ğŸ’¡ Use Case:
- Smart home intrusion alerts  
- Panic detection in surveillance  
- Emergency call systems  

### ğŸ›  Features:
- Preprocessing with **MFCC**
- Model: CNN or MLP classifier
- Real-time or batch audio analysis

### â–¶ï¸ Run:
```bash
python fear_alert/alert_trigger.py --audio path/to/fear_audio.wav
ğŸ—£ï¸ Project 2: Speech-to-Text using Google Speech Command
ğŸ“Œ Description:
Performs simple speech-to-text transcription using voice command clips from the Google Speech Command dataset.

ğŸ’¡ Use Case:
Voice-controlled UI

Command recognition for devices or software

ğŸ›  Features:
Audio preprocessing (MFCC / Spectrogram)

Trained CNN or CRNN model for classification

Outputs recognized keywords as text

â–¶ï¸ Run:
bash
Copy
Edit
python speechtotext/transcribe.py --audio path/to/command.wav
ğŸ”¢ Project 3: Digit Recognition (0â€“9)
ğŸ“Œ Description:
Recognizes digits (zero through nine) spoken in audio using the Google Speech Command dataset.

ğŸ’¡ Use Case:
Spoken digit entry for authentication

Smart calculators

Voice-based phone dialing

ğŸ›  Features:
Trained CNN on MFCC features

Supports inference on custom audio samples

Accuracy > 90% with clean audio

â–¶ï¸ Run:
bash
Copy
Edit
python digitrecog/train_model.py
python digitrecog/predict_digit.py --audio path/to/digit.wav
ğŸ§± Project Structure
Copy
Edit
speech-recognition-suite/
â”œâ”€â”€ fear_alert/
â”‚   â”œâ”€â”€ dataset/
â”‚   â”œâ”€â”€ feature_extract.py
â”‚   â”œâ”€â”€ model.py
â”‚   â””â”€â”€ alert_trigger.py

â”œâ”€â”€ speechtotext/
â”‚   â”œâ”€â”€ dataset/
â”‚   â”œâ”€â”€ train.py
â”‚   â”œâ”€â”€ model.py
â”‚   â””â”€â”€ transcribe.py

â”œâ”€â”€ digitrecog/
â”‚   â”œâ”€â”€ dataset/
â”‚   â”œâ”€â”€ preprocessing.py
â”‚   â”œâ”€â”€ train_model.py
â”‚   â””â”€â”€ predict_digit.py

â”œâ”€â”€ utils/
â”‚   â”œâ”€â”€ audio_utils.py
â”‚   â””â”€â”€ visualization.py

â””â”€â”€ README.md
ğŸ“¦ Installation
Install all dependencies:

bash
Copy
Edit
pip install -r requirements.txt
Key Libraries:

TensorFlow or PyTorch

librosa, numpy, matplotlib

scikit-learn

pyaudio, soundfile

ğŸ“Š Visualizations
Waveforms and Spectrograms

Model performance graphs (loss/accuracy)

Confusion matrices for classification

Run visualizations:

bash
Copy
Edit
python utils/visualization.py
ğŸ”® Future Enhancements
Real-time microphone input

Emotion classification beyond fear (anger, sadness, etc.)

Mobile app and edge deployment (Raspberry Pi)

Multilingual speech support

